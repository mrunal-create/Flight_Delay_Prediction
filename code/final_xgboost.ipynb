{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "#from google.colab import drive\n",
    "#import cupy as cp\n",
    "#import cudf\n",
    "import dask\n",
    "#from dask_ml.preprocessing import Categorizer\n",
    "#import dask.dataframe as dd\n",
    "import pickle  # To save mappings for decoding\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#import dask.array as da\n",
    "from xgboost.dask import DaskXGBRegressor\n",
    "import time \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from sklearn.linear_model import SGDRegressor  # For batch-by-batch linear regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "from dask_ml.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = dd.read_parquet(\"C:/Users/Himanshu/Downloads/proc_data_updated.parquet\",blocksize=\"64MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dtypes dictionary for all columns\n",
    "dtypes = {\n",
    "    'DepTime': 'float16',\n",
    "    'CRSDepTime': 'float16',\n",
    "    'ArrTime': 'float16',\n",
    "    'CRSArrTime': 'float16',\n",
    "    'ArrDelay': 'float16',\n",
    "    'DepDelay': 'float16',\n",
    "    'TaxiIn': 'float16',\n",
    "    'TaxiOut': 'float16',\n",
    "    'CarrierDelay': 'float16',\n",
    "    'WeatherDelay': 'float16',\n",
    "    'NASDelay': 'float16',\n",
    "    'SecurityDelay': 'float16',\n",
    "    'LateAircraftDelay': 'float16'\n",
    "}\n",
    "features = ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime',\n",
    "            'ArrDelay', 'TaxiIn', 'TaxiOut', 'CarrierDelay', 'WeatherDelay',\n",
    "            'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "target = 'DepDelay'\n",
    "# Apply dtypes to the Dask DataFrame\n",
    "data = data.astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>901.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>621.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>627.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>635.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>915.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepTime  CRSDepTime  ArrTime  CRSArrTime  ArrDelay  DepDelay  TaxiIn  \\\n",
       "0    623.0       630.0    901.0       915.0     -14.0      -7.0     7.0   \n",
       "1    621.0       630.0    911.0       915.0      -4.0      -9.0    16.0   \n",
       "2    633.0       630.0    920.0       915.0       5.0       3.0     4.0   \n",
       "3    627.0       630.0    859.0       915.0     -16.0      -3.0     4.0   \n",
       "4    635.0       630.0    918.0       915.0       3.0       5.0     3.0   \n",
       "\n",
       "   TaxiOut  CarrierDelay  WeatherDelay  NASDelay  SecurityDelay  \\\n",
       "0     11.0           0.0           0.0       0.0            0.0   \n",
       "1     16.0           0.0           0.0       0.0            0.0   \n",
       "2     15.0           0.0           0.0       0.0            0.0   \n",
       "3     10.0           0.0           0.0       0.0            0.0   \n",
       "4     13.0           0.0           0.0       0.0            0.0   \n",
       "\n",
       "   LateAircraftDelay  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime',\n",
    "            'ArrDelay', 'TaxiIn', 'TaxiOut', 'CarrierDelay', 'WeatherDelay',\n",
    "            'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "target = 'DepDelay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[features].to_dask_array(lengths=True)\n",
    "y = data[target].to_dask_array(lengths=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#n_partitions = 300, n_worker = 2, threads_per_worker = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 55715 instead\n",
      "  warnings.warn(\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.61 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 269.70 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 275.81 seconds.\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.63 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.63 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:522: RuntimeWarning: overflow encountered in cast\n",
      "  scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1198: RuntimeWarning: overflow encountered in square\n",
      "  weight * (y_true - np.average(y_true, axis=0, weights=sample_weight)) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 64.46044158935547\n",
      "R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# XGBoost related imports\n",
    "from xgboost.dask import DaskXGBRegressor\n",
    "\n",
    "# Metrics for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize Dask Client\n",
    "client = Client(n_workers=2, threads_per_worker=2) # You can specify a scheduler address or leave it for local cluster\n",
    "\n",
    "# Your dataset needs to be loaded as Dask DataFrames (assuming X_train, y_train, X_test, y_test are Dask DataFrames)\n",
    "# Example:\n",
    "# X_train = dd.from_pandas(pandas_X_train, npartitions=4)\n",
    "# y_train = dd.from_pandas(pandas_y_train, npartitions=4)\n",
    "# X_test = dd.from_pandas(pandas_X_test, npartitions=4)\n",
    "# y_test = dd.from_pandas(pandas_y_test, npartitions=4)\n",
    "\n",
    "# Initialize the Dask-XGBoost Regressor\n",
    "xgb_model = DaskXGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3)\n",
    "\n",
    "# Train the Model\n",
    "print(\"Training the model...\")\n",
    "start_time = time.time()  # Start timer\n",
    "\n",
    "with ProgressBar():\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "end_time = time.time()  # End timer\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "\n",
    "# Make Predictions\n",
    "print(\"Predicting...\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Model\n",
    "# y_test and y_pred are already NumPy arrays, no need to call .compute()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "\n",
    "# Shut down the client\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_partitions = 300 with n_worker = 4, threads_per_worker = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 55415 instead\n",
      "  warnings.warn(\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.61 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 269.70 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 188.69 seconds.\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.63 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.63 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:522: RuntimeWarning: overflow encountered in cast\n",
      "  scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1198: RuntimeWarning: overflow encountered in square\n",
      "  weight * (y_true - np.average(y_true, axis=0, weights=sample_weight)) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 64.46044158935547\n",
      "R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# XGBoost related imports\n",
    "from xgboost.dask import DaskXGBRegressor\n",
    "\n",
    "# Metrics for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize Dask Client\n",
    "client = Client(n_workers=4, threads_per_worker=2) # You can specify a scheduler address or leave it for local cluster\n",
    "\n",
    "# Your dataset needs to be loaded as Dask DataFrames (assuming X_train, y_train, X_test, y_test are Dask DataFrames)\n",
    "# Example:\n",
    "# X_train = dd.from_pandas(pandas_X_train, npartitions=4)\n",
    "# y_train = dd.from_pandas(pandas_y_train, npartitions=4)\n",
    "# X_test = dd.from_pandas(pandas_X_test, npartitions=4)\n",
    "# y_test = dd.from_pandas(pandas_y_test, npartitions=4)\n",
    "\n",
    "# Initialize the Dask-XGBoost Regressor\n",
    "xgb_model = DaskXGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3)\n",
    "\n",
    "# Train the Model\n",
    "print(\"Training the model...\")\n",
    "start_time = time.time()  # Start timer\n",
    "\n",
    "with ProgressBar():\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "end_time = time.time()  # End timer\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "\n",
    "# Make Predictions\n",
    "print(\"Predicting...\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Model\n",
    "# y_test and y_pred are already NumPy arrays, no need to call .compute()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "\n",
    "# Shut down the client\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_partitions = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.61 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 269.70 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 163.68 seconds.\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 269.70 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.63 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:522: RuntimeWarning: overflow encountered in cast\n",
      "  scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1198: RuntimeWarning: overflow encountered in square\n",
      "  weight * (y_true - np.average(y_true, axis=0, weights=sample_weight)) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 64.46044158935547\n",
      "R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# XGBoost related imports\n",
    "from xgboost.dask import DaskXGBRegressor\n",
    "\n",
    "# Metrics for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize Dask Client\n",
    "client = Client()  # You can specify a scheduler address or leave it for local cluster\n",
    "\n",
    "# Your dataset needs to be loaded as Dask DataFrames (assuming X_train, y_train, X_test, y_test are Dask DataFrames)\n",
    "# Example:\n",
    "# X_train = dd.from_pandas(pandas_X_train, npartitions=4)\n",
    "# y_train = dd.from_pandas(pandas_y_train, npartitions=4)\n",
    "# X_test = dd.from_pandas(pandas_X_test, npartitions=4)\n",
    "# y_test = dd.from_pandas(pandas_y_test, npartitions=4)\n",
    "\n",
    "# Initialize the Dask-XGBoost Regressor\n",
    "xgb_model = DaskXGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3)\n",
    "\n",
    "# Train the Model\n",
    "print(\"Training the model...\")\n",
    "start_time = time.time()  # Start timer\n",
    "\n",
    "with ProgressBar():\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "end_time = time.time()  # End timer\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "\n",
    "# Make Predictions\n",
    "print(\"Predicting...\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_test = y_test.compute()  # Bring to memory\n",
    "y_pred = y_pred.compute()  # Bring to memory\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Shut down the client\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_partions = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.55 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 269.64 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n",
      "Windows is not officially supported for dask/xgboost, contribution are welcomed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 80.68 seconds.\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 269.64 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\distributed\\client.py:3164: UserWarning: Sending large graph of size 862.56 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:522: RuntimeWarning: overflow encountered in cast\n",
      "  scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n",
      "c:\\Users\\Himanshu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1198: RuntimeWarning: overflow encountered in square\n",
      "  weight * (y_true - np.average(y_true, axis=0, weights=sample_weight)) ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 66.9477767944336\n",
      "R-squared: 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, progress\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# XGBoost related imports\n",
    "from xgboost.dask import DaskXGBRegressor\n",
    "\n",
    "# Metrics for model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize Dask Client\n",
    "client = Client()  # You can specify a scheduler address or leave it for local cluster\n",
    "\n",
    "# Your dataset needs to be loaded as Dask DataFrames (assuming X_train, y_train, X_test, y_test are Dask DataFrames)\n",
    "# Example:\n",
    "# X_train = dd.from_pandas(pandas_X_train, npartitions=4)\n",
    "# y_train = dd.from_pandas(pandas_y_train, npartitions=4)\n",
    "# X_test = dd.from_pandas(pandas_X_test, npartitions=4)\n",
    "# y_test = dd.from_pandas(pandas_y_test, npartitions=4)\n",
    "\n",
    "# Initialize the Dask-XGBoost Regressor\n",
    "xgb_model = DaskXGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3)\n",
    "\n",
    "# Train the Model\n",
    "print(\"Training the model...\")\n",
    "start_time = time.time()  # Start timer\n",
    "\n",
    "with ProgressBar():\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "end_time = time.time()  # End timer\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "\n",
    "# Make Predictions\n",
    "print(\"Predicting...\")\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_test = y_test.compute()  # Bring to memory\n",
    "y_pred = y_pred.compute()  # Bring to memory\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Shut down the client\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
